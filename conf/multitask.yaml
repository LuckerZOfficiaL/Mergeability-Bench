core:
  project_name: model_merging
  storage_dir: ${oc.env:PROJECT_ROOT}/storage
  entity: lzhou00-sapienza-universit-di-roma
  version: 0.0.1
  tags: 
  - dev
  
defaults:
  - hydra: default
  - nn: default
  - train: default
  - merger: weight_avg # iso-c, isotropic, tsv, task_arithmetic, weight_avg, dummy (just uses pretrained), see all options in ./conf/merger
  - benchmark: N8 # N14, N8, N20
  - override hydra/launcher: basic # basic
  - override hydra/job_logging: none
  - override hydra/hydra_logging: none
  - _self_ # as last argument to allow the override of parameters via this main config

# If true, run pairwise merging evaluation for all pairs in the benchmark, instead of merging all of them and evaluate on all tasks
all_pairwise: true

seed_index: 0
num_tasks: ???
eval_on_train: false
number_of_train_batches: 25 # number of batches of the val set, used for grid search
device: 'cuda'



conventions:
  x_key: 'x'
  y_key: 'y'

# compression_ratio = 1 / svd_compress_factor, if null the ratio is set to 1 / num_tasks
svd_compress_factor: null

misc:
  ckpt_path: ${oc.env:MODELS_PATH}/${nn.encoder.model_name}
  pretrained_checkpoint: ${misc.ckpt_path}/base/model.pt
  openclip_cachedir: "${oc.env:MODELS_PATH}/openclip_cache/"
  checkpoint_dir: ${oc.env:MODELS_PATH}/linear_router
  svd_path: "${oc.env:MODELS_PATH}/svd_dict_${nn.encoder.model_name}.pt"
  finetuned_accuracy_path: "${oc.env:PROJECT_ROOT}/results/finetuning/accs.json"
  results_path: "${oc.env:PROJECT_ROOT}/results/${nn.encoder.model_name}/"

# Mergeability metrics configuration
mergeability:
  # OPTION 1: List datasets explicitly (set benchmark_name to null or a custom name)
  # datasets:
  #   - MNIST
  #   - Cars
  # benchmark_name: null  # or "custom_2tasks"

  # OPTION 2: Use a benchmark (e.g., N2, N8, N14, N20) from ./conf/benchmark
  benchmark_name: N8  # Used for output filename
  datasets: ${benchmark_datasets:${mergeability.benchmark_name}}

  metrics: # see options in ./src/model_merging/metrics/mergeability.py, or use "all" to run all metrics.
    - all
  layer_wise: false  # If true, compute all metrics per-layer (saves full breakdown, logs average)
  output_path: "${oc.env:PROJECT_ROOT}/results/mergeability/${nn.encoder.model_name}/"