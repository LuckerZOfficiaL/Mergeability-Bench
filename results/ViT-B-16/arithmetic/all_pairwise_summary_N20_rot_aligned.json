{
    "SUN397__Cars": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7309823632240295,
                "loss/test/SUN397": 0.9258811473846436,
                "normalized_acc/test/SUN397": 0.9270380735397339
            }
        ],
        "Cars": [
            {
                "acc/test/Cars": 0.7627160549163818,
                "loss/test/Cars": 0.6964994072914124,
                "normalized_acc/test/Cars": 0.888969361782074
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7468492090702057,
                "normalized_acc/test/avg": 0.9080037176609039
            }
        ]
    },
    "SUN397__RESISC45": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7331990003585815,
                "loss/test/SUN397": 0.9285914897918701,
                "normalized_acc/test/SUN397": 0.9298492670059204
            }
        ],
        "RESISC45": [
            {
                "acc/test/RESISC45": 0.8857142925262451,
                "loss/test/RESISC45": 0.36129701137542725,
                "normalized_acc/test/RESISC45": 0.9162561893463135
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8094566464424133,
                "normalized_acc/test/avg": 0.9230527281761169
            }
        ]
    },
    "SUN397__EuroSAT": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7302770614624023,
                "loss/test/SUN397": 0.924424409866333,
                "normalized_acc/test/SUN397": 0.9261436462402344
            }
        ],
        "EuroSAT": [
            {
                "acc/test/EuroSAT": 0.9725925922393799,
                "loss/test/EuroSAT": 0.10783335566520691,
                "normalized_acc/test/EuroSAT": 0.9816822409629822
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8514348268508911,
                "normalized_acc/test/avg": 0.9539129436016083
            }
        ]
    },
    "SUN397__SVHN": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7268009781837463,
                "loss/test/SUN397": 0.9492768049240112,
                "normalized_acc/test/SUN397": 0.9217352271080017
            }
        ],
        "SVHN": [
            {
                "acc/test/SVHN": 0.9316994547843933,
                "loss/test/SVHN": 0.31548652052879333,
                "normalized_acc/test/SVHN": 0.95570969581604
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8292502164840698,
                "normalized_acc/test/avg": 0.9387224614620209
            }
        ]
    },
    "SUN397__GTSRB": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7301259636878967,
                "loss/test/SUN397": 0.9272653460502625,
                "normalized_acc/test/SUN397": 0.9259520173072815
            }
        ],
        "GTSRB": [
            {
                "acc/test/GTSRB": 0.9040380120277405,
                "loss/test/GTSRB": 0.431654155254364,
                "normalized_acc/test/GTSRB": 0.9139518141746521
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8170819878578186,
                "normalized_acc/test/avg": 0.9199519157409668
            }
        ]
    },
    "SUN397__MNIST": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7260453104972839,
                "loss/test/SUN397": 0.9461367726325989,
                "normalized_acc/test/SUN397": 0.920776903629303
            }
        ],
        "MNIST": [
            {
                "acc/test/MNIST": 0.9891999959945679,
                "loss/test/MNIST": 0.09709853678941727,
                "normalized_acc/test/MNIST": 0.9926743507385254
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8576226532459259,
                "normalized_acc/test/avg": 0.9567256271839142
            }
        ]
    },
    "SUN397__DTD": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.734559178352356,
                "loss/test/SUN397": 0.9287616014480591,
                "normalized_acc/test/SUN397": 0.9315742254257202
            }
        ],
        "DTD": [
            {
                "acc/test/DTD": 0.6234042644500732,
                "loss/test/DTD": 1.3272873163223267,
                "normalized_acc/test/DTD": 0.7522464394569397
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6789817214012146,
                "normalized_acc/test/avg": 0.84191033244133
            }
        ]
    },
    "SUN397__Flowers102": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7356171011924744,
                "loss/test/SUN397": 0.9117785692214966,
                "normalized_acc/test/SUN397": 0.9329159259796143
            }
        ],
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.8014311194419861,
                "loss/test/Flowers102": 0.8325906991958618,
                "normalized_acc/test/Flowers102": 0.8505350351333618
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7685241103172302,
                "normalized_acc/test/avg": 0.891725480556488
            }
        ]
    },
    "SUN397__PCAM": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7242821455001831,
                "loss/test/SUN397": 0.9396529793739319,
                "normalized_acc/test/SUN397": 0.9185408353805542
            }
        ],
        "PCAM": [
            {
                "acc/test/PCAM": 0.811798095703125,
                "loss/test/PCAM": 0.39769187569618225,
                "normalized_acc/test/PCAM": 0.9149726629257202
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.768040120601654,
                "normalized_acc/test/avg": 0.9167567491531372
            }
        ]
    },
    "SUN397__FER2013": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7317380309104919,
                "loss/test/SUN397": 0.9243792295455933,
                "normalized_acc/test/SUN397": 0.9279964566230774
            }
        ],
        "FER2013": [
            {
                "acc/test/FER2013": 0.6813875436782837,
                "loss/test/FER2013": 0.9248643517494202,
                "normalized_acc/test/FER2013": 0.9242252111434937
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7065627872943878,
                "normalized_acc/test/avg": 0.9261108338832855
            }
        ]
    },
    "SUN397__OxfordIIITPet": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7340553998947144,
                "loss/test/SUN397": 0.9194678068161011,
                "normalized_acc/test/SUN397": 0.9309353232383728
            }
        ],
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9389479160308838,
                "loss/test/OxfordIIITPet": 0.18220967054367065,
                "normalized_acc/test/OxfordIIITPet": 0.9879552125930786
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8365016579627991,
                "normalized_acc/test/avg": 0.9594452679157257
            }
        ]
    },
    "SUN397__STL10": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7304785847663879,
                "loss/test/SUN397": 0.9134352207183838,
                "normalized_acc/test/SUN397": 0.9263991713523865
            }
        ],
        "STL10": [
            {
                "acc/test/STL10": 0.9898750185966492,
                "loss/test/STL10": 0.03746437653899193,
                "normalized_acc/test/STL10": 1.002024531364441
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8601768016815186,
                "normalized_acc/test/avg": 0.9642118513584137
            }
        ]
    },
    "SUN397__CIFAR100": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7304282188415527,
                "loss/test/SUN397": 0.9419718980789185,
                "normalized_acc/test/SUN397": 0.926335334777832
            }
        ],
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8361999988555908,
                "loss/test/CIFAR100": 0.6191487908363342,
                "normalized_acc/test/CIFAR100": 0.9367088675498962
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7833141088485718,
                "normalized_acc/test/avg": 0.9315221011638641
            }
        ]
    },
    "SUN397__CIFAR10": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7285138368606567,
                "loss/test/SUN397": 0.9238429069519043,
                "normalized_acc/test/SUN397": 0.923907458782196
            }
        ],
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9763000011444092,
                "loss/test/CIFAR10": 0.07821992039680481,
                "normalized_acc/test/CIFAR10": 0.9946006536483765
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.852406919002533,
                "normalized_acc/test/avg": 0.9592540562152863
            }
        ]
    },
    "SUN397__Food101": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7294206619262695,
                "loss/test/SUN397": 0.9272236227989197,
                "normalized_acc/test/SUN397": 0.9250575304031372
            }
        ],
        "Food101": [
            {
                "acc/test/Food101": 0.9169901013374329,
                "loss/test/Food101": 0.29698610305786133,
                "normalized_acc/test/Food101": 1.008800983428955
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8232053816318512,
                "normalized_acc/test/avg": 0.9669292569160461
            }
        ]
    },
    "SUN397__FashionMNIST": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7286146283149719,
                "loss/test/SUN397": 0.9246866106987,
                "normalized_acc/test/SUN397": 0.9240353107452393
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.9025999903678894,
                "loss/test/FashionMNIST": 0.28069019317626953,
                "normalized_acc/test/FashionMNIST": 0.9481092095375061
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8156073093414307,
                "normalized_acc/test/avg": 0.9360722601413727
            }
        ]
    },
    "SUN397__EMNIST": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7303274273872375,
                "loss/test/SUN397": 0.9286433458328247,
                "normalized_acc/test/SUN397": 0.9262074828147888
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9904000163078308,
                "loss/test/EMNIST": 0.12576556205749512,
                "normalized_acc/test/EMNIST": 0.9960776567459106
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8603637218475342,
                "normalized_acc/test/avg": 0.9611425697803497
            }
        ]
    },
    "SUN397__KMNIST": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7300755381584167,
                "loss/test/SUN397": 0.9289013147354126,
                "normalized_acc/test/SUN397": 0.9258880615234375
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.510699987411499,
                "loss/test/KMNIST": 1.7044273614883423,
                "normalized_acc/test/KMNIST": 0.5192679166793823
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6203877627849579,
                "normalized_acc/test/avg": 0.7225779891014099
            }
        ]
    },
    "SUN397__RenderedSST2": {
        "SUN397": [
            {
                "acc/test/SUN397": 0.7321914434432983,
                "loss/test/SUN397": 0.9134615063667297,
                "normalized_acc/test/SUN397": 0.9285714626312256
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7473915219306946,
                "loss/test/RenderedSST2": 0.5169987678527832,
                "normalized_acc/test/RenderedSST2": 0.9686832427978516
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7397914826869965,
                "normalized_acc/test/avg": 0.9486273527145386
            }
        ]
    },
    "Cars__RESISC45": {
        "Cars": [
            {
                "acc/test/Cars": 0.7619699239730835,
                "loss/test/Cars": 0.6965187788009644,
                "normalized_acc/test/Cars": 0.888099730014801
            }
        ],
        "RESISC45": [
            {
                "acc/test/RESISC45": 0.8871428370475769,
                "loss/test/RESISC45": 0.3546631336212158,
                "normalized_acc/test/RESISC45": 0.9177339673042297
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8245563805103302,
                "normalized_acc/test/avg": 0.9029168486595154
            }
        ]
    },
    "Cars__EuroSAT": {
        "Cars": [
            {
                "acc/test/Cars": 0.7598557472229004,
                "loss/test/Cars": 0.6966277360916138,
                "normalized_acc/test/Cars": 0.8856356143951416
            }
        ],
        "EuroSAT": [
            {
                "acc/test/EuroSAT": 0.9744444489479065,
                "loss/test/EuroSAT": 0.1163015067577362,
                "normalized_acc/test/EuroSAT": 0.9835514426231384
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8671500980854034,
                "normalized_acc/test/avg": 0.93459352850914
            }
        ]
    },
    "Cars__SVHN": {
        "Cars": [
            {
                "acc/test/Cars": 0.7617211937904358,
                "loss/test/Cars": 0.6982636451721191,
                "normalized_acc/test/Cars": 0.8878098130226135
            }
        ],
        "SVHN": [
            {
                "acc/test/SVHN": 0.9316994547843933,
                "loss/test/SVHN": 0.32776138186454773,
                "normalized_acc/test/SVHN": 0.95570969581604
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8467103242874146,
                "normalized_acc/test/avg": 0.9217597544193268
            }
        ]
    },
    "Cars__GTSRB": {
        "Cars": [
            {
                "acc/test/Cars": 0.7707996368408203,
                "loss/test/Cars": 0.6730368733406067,
                "normalized_acc/test/Cars": 0.89839106798172
            }
        ],
        "GTSRB": [
            {
                "acc/test/GTSRB": 0.9007917642593384,
                "loss/test/GTSRB": 0.45055636763572693,
                "normalized_acc/test/GTSRB": 0.9106699824333191
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8357957005500793,
                "normalized_acc/test/avg": 0.9045305252075195
            }
        ]
    },
    "Cars__MNIST": {
        "Cars": [
            {
                "acc/test/Cars": 0.7572441101074219,
                "loss/test/Cars": 0.703119695186615,
                "normalized_acc/test/Cars": 0.8825916647911072
            }
        ],
        "MNIST": [
            {
                "acc/test/MNIST": 0.989300012588501,
                "loss/test/MNIST": 0.10387393832206726,
                "normalized_acc/test/MNIST": 0.9927747249603271
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8732720613479614,
                "normalized_acc/test/avg": 0.9376831948757172
            }
        ]
    },
    "Cars__DTD": {
        "Cars": [
            {
                "acc/test/Cars": 0.7679393291473389,
                "loss/test/Cars": 0.6838963627815247,
                "normalized_acc/test/Cars": 0.8950572609901428
            }
        ],
        "DTD": [
            {
                "acc/test/DTD": 0.63882976770401,
                "loss/test/DTD": 1.2509596347808838,
                "normalized_acc/test/DTD": 0.7708600163459778
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7033845484256744,
                "normalized_acc/test/avg": 0.8329586386680603
            }
        ]
    },
    "Cars__Flowers102": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 13.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.37 GiB memory in use. Process 3146572 has 508.00 MiB memory in use. Process 3668488 has 11.07 GiB memory in use. Of the allocated memory 1.76 GiB is allocated by PyTorch, and 119.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "Cars__PCAM": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 13.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.37 GiB memory in use. Process 3146572 has 504.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.76 GiB is allocated by PyTorch, and 119.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "Cars__FER2013": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 89.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.82 GiB memory in use. Process 3146572 has 986.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.28 GiB is allocated by PyTorch, and 58.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "Cars__OxfordIIITPet": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 51.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.79 GiB memory in use. Process 3146572 has 1.04 GiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.23 GiB is allocated by PyTorch, and 71.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "Cars__STL10": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 209.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.10 GiB memory in use. Process 3146572 has 580.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.54 GiB is allocated by PyTorch, and 74.42 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "Cars__CIFAR100": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 99.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.29 GiB memory in use. Process 3146572 has 504.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.72 GiB is allocated by PyTorch, and 78.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "Cars__CIFAR10": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 275.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.11 GiB memory in use. Process 3146572 has 504.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.42 GiB is allocated by PyTorch, and 206.40 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "Cars__Food101": {
        "error": "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 27.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.88 GiB memory in use. Process 3146572 has 986.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.32 GiB is allocated by PyTorch, and 72.17 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "Cars__FashionMNIST": {
        "error": "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 73.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.31 GiB memory in use. Process 3146572 has 504.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.74 GiB is allocated by PyTorch, and 79.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "Cars__EMNIST": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 93.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.29 GiB memory in use. Process 3146572 has 504.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.64 GiB is allocated by PyTorch, and 157.77 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "Cars__KMNIST": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 121.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.82 GiB memory in use. Process 3146572 has 952.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.28 GiB is allocated by PyTorch, and 58.28 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "Cars__RenderedSST2": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 55.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.79 GiB memory in use. Process 3146572 has 1.03 GiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.23 GiB is allocated by PyTorch, and 71.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__EuroSAT": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 59.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.32 GiB memory in use. Process 3146572 has 504.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.76 GiB is allocated by PyTorch, and 65.97 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__SVHN": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 95.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.29 GiB memory in use. Process 3146572 has 504.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.72 GiB is allocated by PyTorch, and 78.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__GTSRB": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 197.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.18 GiB memory in use. Process 3146572 has 504.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.42 GiB is allocated by PyTorch, and 279.20 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__MNIST": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 59.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.32 GiB memory in use. Process 3146572 has 504.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.76 GiB is allocated by PyTorch, and 64.59 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__DTD": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 95.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.28 GiB memory in use. Process 3146572 has 504.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.72 GiB is allocated by PyTorch, and 76.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__Flowers102": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 95.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.28 GiB memory in use. Process 3146572 has 504.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.72 GiB is allocated by PyTorch, and 76.60 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__PCAM": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 117.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.82 GiB memory in use. Process 3146572 has 952.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.27 GiB is allocated by PyTorch, and 58.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__FER2013": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 203.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.10 GiB memory in use. Process 3146572 has 580.00 MiB memory in use. Process 3668488 has 11.08 GiB memory in use. Of the allocated memory 1.54 GiB is allocated by PyTorch, and 74.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__OxfordIIITPet": {
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 9.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.21 GiB memory in use. Process 3146572 has 580.00 MiB memory in use. Process 3668488 has 11.17 GiB memory in use. Of the allocated memory 1.65 GiB is allocated by PyTorch, and 70.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__STL10": {
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 9.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.21 GiB memory in use. Process 3146572 has 580.00 MiB memory in use. Process 3668488 has 11.17 GiB memory in use. Of the allocated memory 1.65 GiB is allocated by PyTorch, and 70.69 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__CIFAR100": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 223.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.61 GiB memory in use. Process 3146572 has 980.00 MiB memory in use. Process 3668488 has 11.17 GiB memory in use. Of the allocated memory 1.05 GiB is allocated by PyTorch, and 66.70 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__CIFAR10": {
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 23.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.73 GiB memory in use. Process 3146572 has 1.03 GiB memory in use. Process 3668488 has 11.17 GiB memory in use. Of the allocated memory 1.17 GiB is allocated by PyTorch, and 65.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__Food101": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 95.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.12 GiB memory in use. Process 3146572 has 580.00 MiB memory in use. Process 3668488 has 11.17 GiB memory in use. Of the allocated memory 1.55 GiB is allocated by PyTorch, and 85.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__FashionMNIST": {
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 9.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.21 GiB memory in use. Process 3146572 has 580.00 MiB memory in use. Process 3668488 has 11.17 GiB memory in use. Of the allocated memory 1.65 GiB is allocated by PyTorch, and 70.71 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "RESISC45__EMNIST": {
        "RESISC45": [
            {
                "acc/test/RESISC45": 0.8785714507102966,
                "loss/test/RESISC45": 0.3842919170856476,
                "normalized_acc/test/RESISC45": 0.9088670611381531
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9897000193595886,
                "loss/test/EMNIST": 0.13226225972175598,
                "normalized_acc/test/EMNIST": 0.9953736662864685
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9341357350349426,
                "normalized_acc/test/avg": 0.9521203637123108
            }
        ]
    },
    "RESISC45__KMNIST": {
        "RESISC45": [
            {
                "acc/test/RESISC45": 0.8792063593864441,
                "loss/test/RESISC45": 0.38504329323768616,
                "normalized_acc/test/RESISC45": 0.9095238447189331
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.5012000203132629,
                "loss/test/KMNIST": 1.7325191497802734,
                "normalized_acc/test/KMNIST": 0.5096085667610168
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6902031898498535,
                "normalized_acc/test/avg": 0.709566205739975
            }
        ]
    },
    "RESISC45__RenderedSST2": {
        "RESISC45": [
            {
                "acc/test/RESISC45": 0.8926984071731567,
                "loss/test/RESISC45": 0.3458631634712219,
                "normalized_acc/test/RESISC45": 0.9234811663627625
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7419000267982483,
                "loss/test/RenderedSST2": 0.5344887971878052,
                "normalized_acc/test/RenderedSST2": 0.9615657925605774
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8172992169857025,
                "normalized_acc/test/avg": 0.9425234794616699
            }
        ]
    },
    "EuroSAT__SVHN": {
        "EuroSAT": [
            {
                "acc/test/EuroSAT": 0.9433333277702332,
                "loss/test/EuroSAT": 0.21583499014377594,
                "normalized_acc/test/EuroSAT": 0.9521495699882507
            }
        ],
        "SVHN": [
            {
                "acc/test/SVHN": 0.9203288555145264,
                "loss/test/SVHN": 0.367815226316452,
                "normalized_acc/test/SVHN": 0.9440460801124573
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9318310916423798,
                "normalized_acc/test/avg": 0.948097825050354
            }
        ]
    },
    "EuroSAT__GTSRB": {
        "EuroSAT": [
            {
                "acc/test/EuroSAT": 0.9585185050964355,
                "loss/test/EuroSAT": 0.1539772003889084,
                "normalized_acc/test/EuroSAT": 0.9674766659736633
            }
        ],
        "GTSRB": [
            {
                "acc/test/GTSRB": 0.8675376176834106,
                "loss/test/GTSRB": 0.5393350720405579,
                "normalized_acc/test/GTSRB": 0.8770511746406555
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9130280613899231,
                "normalized_acc/test/avg": 0.9222639203071594
            }
        ]
    },
    "EuroSAT__MNIST": {
        "error": "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 81.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.31 GiB memory in use. Process 3146572 has 1.69 GiB memory in use. Process 3668488 has 9.88 GiB memory in use. Of the allocated memory 1.74 GiB is allocated by PyTorch, and 80.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__DTD": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 42.25 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.40 GiB memory in use. Process 3146572 has 1.22 GiB memory in use. Process 3668488 has 9.88 GiB memory in use. Process 1949407 has 416.00 MiB memory in use. Of the allocated memory 1.83 GiB is allocated by PyTorch, and 81.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__Flowers102": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 301.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.92 GiB memory in use. Process 3146572 has 876.00 MiB memory in use. Process 3668488 has 9.88 GiB memory in use. Of the allocated memory 2.12 GiB is allocated by PyTorch, and 314.13 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__PCAM": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 89.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.13 GiB memory in use. Process 3146572 has 876.00 MiB memory in use. Process 3668488 has 9.88 GiB memory in use. Of the allocated memory 2.32 GiB is allocated by PyTorch, and 322.35 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__FER2013": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 189.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.60 GiB memory in use. Process 3146572 has 1.29 GiB memory in use. Process 3668488 has 9.88 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 82.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__OxfordIIITPet": {
        "error": "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 27.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.88 GiB memory in use. Process 3146572 has 1.29 GiB memory in use. Process 3668488 has 9.76 GiB memory in use. Of the allocated memory 2.30 GiB is allocated by PyTorch, and 87.58 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__STL10": {
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 25.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.58 GiB memory in use. Process 3146572 has 2.58 GiB memory in use. Process 3668488 has 9.76 GiB memory in use. Of the allocated memory 1.01 GiB is allocated by PyTorch, and 82.04 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__CIFAR100": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 137.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.35 GiB memory in use. Process 3146572 has 728.00 MiB memory in use. Process 3668488 has 9.76 GiB memory in use. Of the allocated memory 2.54 GiB is allocated by PyTorch, and 322.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__CIFAR10": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 235.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.82 GiB memory in use. Process 3146572 has 1.15 GiB memory in use. Process 3668488 has 9.76 GiB memory in use. Of the allocated memory 2.03 GiB is allocated by PyTorch, and 296.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__Food101": {
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 21.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.24 GiB memory in use. Process 3146572 has 952.00 MiB memory in use. Process 3668488 has 9.76 GiB memory in use. Of the allocated memory 2.66 GiB is allocated by PyTorch, and 90.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__FashionMNIST": {
        "EuroSAT": [
            {
                "acc/test/EuroSAT": 0.9507407546043396,
                "loss/test/EuroSAT": 0.1905302107334137,
                "normalized_acc/test/EuroSAT": 0.9596261978149414
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8859999775886536,
                "loss/test/FashionMNIST": 0.3270982503890991,
                "normalized_acc/test/FashionMNIST": 0.9306722283363342
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9183703660964966,
                "normalized_acc/test/avg": 0.9451492130756378
            }
        ]
    },
    "EuroSAT__EMNIST": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 209.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.35 GiB memory in use. Process 3146572 has 654.00 MiB memory in use. Process 3668488 has 9.76 GiB memory in use. Of the allocated memory 2.54 GiB is allocated by PyTorch, and 322.33 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__KMNIST": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 13.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.82 GiB memory in use. Process 3146572 has 1.36 GiB memory in use. Process 3668488 has 9.76 GiB memory in use. Of the allocated memory 2.18 GiB is allocated by PyTorch, and 148.19 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "EuroSAT__RenderedSST2": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 95.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.02 GiB memory in use. Process 3146572 has 1.07 GiB memory in use. Process 3668488 has 9.76 GiB memory in use. Of the allocated memory 2.44 GiB is allocated by PyTorch, and 89.83 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__GTSRB": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 169.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.92 GiB memory in use. Process 3146572 has 1.10 GiB memory in use. Process 3668488 has 9.77 GiB memory in use. Of the allocated memory 2.12 GiB is allocated by PyTorch, and 314.25 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__MNIST": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 73.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.90 GiB memory in use. Process 3146572 has 1.22 GiB memory in use. Process 3668488 has 9.77 GiB memory in use. Of the allocated memory 2.20 GiB is allocated by PyTorch, and 214.16 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__DTD": {
        "SVHN": [
            {
                "acc/test/SVHN": 0.9350031018257141,
                "loss/test/SVHN": 0.3020652234554291,
                "normalized_acc/test/SVHN": 0.9590984582901001
            }
        ],
        "DTD": [
            {
                "acc/test/DTD": 0.6223404407501221,
                "loss/test/DTD": 1.3354328870773315,
                "normalized_acc/test/DTD": 0.7509627938270569
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7786717712879181,
                "normalized_acc/test/avg": 0.8550306260585785
            }
        ]
    },
    "SVHN__Flowers102": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 281.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.05 GiB memory in use. Process 3146572 has 876.00 MiB memory in use. Process 3668488 has 9.77 GiB memory in use. Of the allocated memory 2.25 GiB is allocated by PyTorch, and 316.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__PCAM": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 157.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.10 GiB memory in use. Process 3146572 has 950.00 MiB memory in use. Process 3668488 has 9.77 GiB memory in use. Of the allocated memory 2.32 GiB is allocated by PyTorch, and 292.31 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__FER2013": {
        "error": "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 33.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.53 GiB memory in use. Process 3146572 has 2.62 GiB memory in use. Process 3668488 has 9.77 GiB memory in use. Of the allocated memory 1001.86 MiB is allocated by PyTorch, and 64.14 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__OxfordIIITPet": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 203.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.42 GiB memory in use. Process 3146572 has 580.00 MiB memory in use. Process 3668488 has 9.77 GiB memory in use. Of the allocated memory 2.61 GiB is allocated by PyTorch, and 320.02 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__STL10": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 303.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.89 GiB memory in use. Process 3146572 has 1024.00 MiB memory in use. Process 3668488 has 9.77 GiB memory in use. Of the allocated memory 2.11 GiB is allocated by PyTorch, and 294.05 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__CIFAR100": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 95.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.82 GiB memory in use. Process 3146572 has 950.00 MiB memory in use. Process 3668488 has 11.11 GiB memory in use. Of the allocated memory 1.28 GiB is allocated by PyTorch, and 56.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__CIFAR10": {
        "error": "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 29.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.03 GiB memory in use. Process 3146572 has 802.00 MiB memory in use. Process 3668488 has 11.11 GiB memory in use. Of the allocated memory 1.47 GiB is allocated by PyTorch, and 72.15 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__Food101": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 19.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.86 GiB memory in use. Process 3146572 has 986.00 MiB memory in use. Process 3668488 has 11.11 GiB memory in use. Of the allocated memory 1.30 GiB is allocated by PyTorch, and 70.23 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__FashionMNIST": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 93.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.82 GiB memory in use. Process 3146572 has 950.00 MiB memory in use. Process 3668488 has 11.11 GiB memory in use. Of the allocated memory 1.28 GiB is allocated by PyTorch, and 56.39 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__EMNIST": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 177.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.10 GiB memory in use. Process 3146572 has 580.00 MiB memory in use. Process 3668488 has 11.11 GiB memory in use. Of the allocated memory 1.54 GiB is allocated by PyTorch, and 72.54 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__KMNIST": {
        "error": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 9.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.27 GiB memory in use. Process 3146572 has 580.00 MiB memory in use. Process 3668488 has 11.11 GiB memory in use. Of the allocated memory 1.70 GiB is allocated by PyTorch, and 76.62 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "SVHN__RenderedSST2": {
        "SVHN": [
            {
                "acc/test/SVHN": 0.9347726106643677,
                "loss/test/SVHN": 0.3233260214328766,
                "normalized_acc/test/SVHN": 0.9588620662689209
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7419000267982483,
                "loss/test/RenderedSST2": 0.5294346213340759,
                "normalized_acc/test/RenderedSST2": 0.9615657925605774
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.838336318731308,
                "normalized_acc/test/avg": 0.9602139294147491
            }
        ]
    },
    "GTSRB__MNIST": {
        "GTSRB": [
            {
                "acc/test/GTSRB": 0.8709421753883362,
                "loss/test/GTSRB": 0.49416327476501465,
                "normalized_acc/test/GTSRB": 0.8804930448532104
            }
        ],
        "MNIST": [
            {
                "acc/test/MNIST": 0.9894000291824341,
                "loss/test/MNIST": 0.0928964614868164,
                "normalized_acc/test/MNIST": 0.9928750991821289
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9301711022853851,
                "normalized_acc/test/avg": 0.9366840720176697
            }
        ]
    },
    "GTSRB__DTD": {
        "GTSRB": [
            {
                "acc/test/GTSRB": 0.9021377563476562,
                "loss/test/GTSRB": 0.43522167205810547,
                "normalized_acc/test/GTSRB": 0.9120307564735413
            }
        ],
        "DTD": [
            {
                "acc/test/DTD": 0.6308510899543762,
                "loss/test/DTD": 1.2912371158599854,
                "normalized_acc/test/DTD": 0.7612323760986328
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7664944231510162,
                "normalized_acc/test/avg": 0.836631566286087
            }
        ]
    },
    "GTSRB__Flowers102": {
        "GTSRB": [
            {
                "acc/test/GTSRB": 0.9059382677078247,
                "loss/test/GTSRB": 0.44567620754241943,
                "normalized_acc/test/GTSRB": 0.9158729314804077
            }
        ],
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.793624997138977,
                "loss/test/Flowers102": 0.8634433746337891,
                "normalized_acc/test/Flowers102": 0.8422505855560303
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8497816324234009,
                "normalized_acc/test/avg": 0.879061758518219
            }
        ]
    },
    "GTSRB__PCAM": {
        "GTSRB": [
            {
                "acc/test/GTSRB": 0.8655582070350647,
                "loss/test/GTSRB": 0.6250355839729309,
                "normalized_acc/test/GTSRB": 0.8750500679016113
            }
        ],
        "PCAM": [
            {
                "acc/test/PCAM": 0.759674072265625,
                "loss/test/PCAM": 0.48474791646003723,
                "normalized_acc/test/PCAM": 0.856224000453949
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8126161396503448,
                "normalized_acc/test/avg": 0.8656370341777802
            }
        ]
    },
    "GTSRB__FER2013": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 285.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.77 GiB memory in use. Process 3146572 has 508.00 MiB memory in use. Process 3668488 has 9.41 GiB memory in use. Of the allocated memory 2.96 GiB is allocated by PyTorch, and 327.61 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "GTSRB__OxfordIIITPet": {
        "GTSRB": [
            {
                "acc/test/GTSRB": 0.8972288370132446,
                "loss/test/GTSRB": 0.4642989933490753,
                "normalized_acc/test/GTSRB": 0.9070680141448975
            }
        ],
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9345870614051819,
                "loss/test/OxfordIIITPet": 0.19171880185604095,
                "normalized_acc/test/OxfordIIITPet": 0.9833667278289795
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9159079492092133,
                "normalized_acc/test/avg": 0.9452173709869385
            }
        ]
    },
    "GTSRB__STL10": {
        "GTSRB": [
            {
                "acc/test/GTSRB": 0.8954077363014221,
                "loss/test/GTSRB": 0.4885375201702118,
                "normalized_acc/test/GTSRB": 0.9052269458770752
            }
        ],
        "STL10": [
            {
                "acc/test/STL10": 0.987625002861023,
                "loss/test/STL10": 0.04087346792221069,
                "normalized_acc/test/STL10": 0.9997469782829285
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9415163695812225,
                "normalized_acc/test/avg": 0.9524869620800018
            }
        ]
    },
    "GTSRB__CIFAR100": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 199.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.32 GiB memory in use. Process 3146572 has 1.03 GiB memory in use. Process 3668488 has 9.41 GiB memory in use. Of the allocated memory 2.54 GiB is allocated by PyTorch, and 294.00 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "GTSRB__CIFAR10": {
        "GTSRB": [
            {
                "acc/test/GTSRB": 0.8595407605171204,
                "loss/test/GTSRB": 0.5708245635032654,
                "normalized_acc/test/GTSRB": 0.8689666390419006
            }
        ],
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9743000268936157,
                "loss/test/CIFAR10": 0.08526571094989777,
                "normalized_acc/test/CIFAR10": 0.9925631880760193
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.916920393705368,
                "normalized_acc/test/avg": 0.93076491355896
            }
        ]
    },
    "GTSRB__Food101": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 119.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.35 GiB memory in use. Process 3146572 has 728.00 MiB memory in use. Process 3668488 has 9.78 GiB memory in use. Of the allocated memory 2.54 GiB is allocated by PyTorch, and 319.91 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "GTSRB__FashionMNIST": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 43.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.88 GiB memory in use. Process 3146572 has 2.25 GiB memory in use. Process 3668488 has 9.78 GiB memory in use. Of the allocated memory 1.32 GiB is allocated by PyTorch, and 70.57 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "GTSRB__EMNIST": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 291.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.39 GiB memory in use. Process 3146572 has 508.00 MiB memory in use. Process 3668488 has 9.78 GiB memory in use. Of the allocated memory 2.61 GiB is allocated by PyTorch, and 293.99 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "GTSRB__KMNIST": {
        "error": "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 19.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.53 GiB memory in use. Process 3146572 has 2.62 GiB memory in use. Process 3668488 has 9.78 GiB memory in use. Of the allocated memory 1001.93 MiB is allocated by PyTorch, and 64.07 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "GTSRB__RenderedSST2": {
        "error": "CUDA out of memory. Tried to allocate 98.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 69.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.55 GiB memory in use. Process 3146572 has 2.55 GiB memory in use. Process 3668488 has 9.78 GiB memory in use. Of the allocated memory 1023.45 MiB is allocated by PyTorch, and 64.55 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "MNIST__DTD": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 263.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.42 GiB memory in use. Process 3146572 has 508.00 MiB memory in use. Process 3668488 has 9.78 GiB memory in use. Of the allocated memory 2.61 GiB is allocated by PyTorch, and 320.01 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "MNIST__Flowers102": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 47.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 2.83 GiB memory in use. Process 3146572 has 1.29 GiB memory in use. Process 3668488 has 9.78 GiB memory in use. Of the allocated memory 2.25 GiB is allocated by PyTorch, and 91.93 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "MNIST__PCAM": {
        "error": "CUDA out of memory. Tried to allocate 74.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 41.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 1.39 GiB memory in use. Process 3146572 has 2.74 GiB memory in use. Process 3668488 has 9.79 GiB memory in use. Of the allocated memory 853.48 MiB is allocated by PyTorch, and 64.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "MNIST__FER2013": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 187.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.35 GiB memory in use. Process 3146572 has 654.00 MiB memory in use. Process 3668488 has 9.79 GiB memory in use. Of the allocated memory 2.54 GiB is allocated by PyTorch, and 320.09 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "MNIST__OxfordIIITPet": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 139.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.10 GiB memory in use. Process 3146572 has 950.00 MiB memory in use. Process 3668488 has 9.79 GiB memory in use. Of the allocated memory 2.32 GiB is allocated by PyTorch, and 294.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "MNIST__STL10": {
        "error": "CUDA out of memory. Tried to allocate 222.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 223.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.31 GiB memory in use. Process 3146572 has 654.00 MiB memory in use. Process 3668488 has 9.79 GiB memory in use. Of the allocated memory 2.67 GiB is allocated by PyTorch, and 153.46 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "MNIST__CIFAR100": {
        "MNIST": [
            {
                "acc/test/MNIST": 0.9884999990463257,
                "loss/test/MNIST": 0.10402009636163712,
                "normalized_acc/test/MNIST": 0.9919719099998474
            }
        ],
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8216999769210815,
                "loss/test/CIFAR100": 0.6706206798553467,
                "normalized_acc/test/CIFAR100": 0.9204659461975098
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9050999879837036,
                "normalized_acc/test/avg": 0.9562189280986786
            }
        ]
    },
    "MNIST__CIFAR10": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 183.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.35 GiB memory in use. Process 3146572 has 654.00 MiB memory in use. Process 3668488 has 9.79 GiB memory in use. Of the allocated memory 2.54 GiB is allocated by PyTorch, and 320.08 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "MNIST__Food101": {
        "error": "CUDA out of memory. Tried to allocate 296.00 MiB. GPU 0 has a total capacity of 79.25 GiB of which 135.81 MiB is free. Process 301280 has 64.57 GiB memory in use. Process 2081303 has 692.00 MiB memory in use. Process 3088522 has 3.10 GiB memory in use. Process 3146572 has 950.00 MiB memory in use. Process 3668488 has 9.79 GiB memory in use. Of the allocated memory 2.32 GiB is allocated by PyTorch, and 294.06 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
    },
    "MNIST__FashionMNIST": {
        "MNIST": [
            {
                "acc/test/MNIST": 0.9879999756813049,
                "loss/test/MNIST": 0.13281118869781494,
                "normalized_acc/test/MNIST": 0.9914700984954834
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8725000023841858,
                "loss/test/FashionMNIST": 0.3781123459339142,
                "normalized_acc/test/FashionMNIST": 0.9164915680885315
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9302499890327454,
                "normalized_acc/test/avg": 0.9539808332920074
            }
        ]
    },
    "MNIST__EMNIST": {
        "MNIST": [
            {
                "acc/test/MNIST": 0.9958000183105469,
                "loss/test/MNIST": 0.037346962839365005,
                "normalized_acc/test/MNIST": 0.999297559261322
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9970999956130981,
                "loss/test/EMNIST": 0.04454461857676506,
                "normalized_acc/test/EMNIST": 1.002816081047058
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9964500069618225,
                "normalized_acc/test/avg": 1.00105682015419
            }
        ]
    },
    "MNIST__KMNIST": {
        "MNIST": [
            {
                "acc/test/MNIST": 0.9861999750137329,
                "loss/test/MNIST": 0.10458223521709442,
                "normalized_acc/test/MNIST": 0.9896637797355652
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.47679999470710754,
                "loss/test/KMNIST": 1.728966236114502,
                "normalized_acc/test/KMNIST": 0.48479917645454407
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7314999848604202,
                "normalized_acc/test/avg": 0.7372314780950546
            }
        ]
    },
    "MNIST__RenderedSST2": {
        "MNIST": [
            {
                "acc/test/MNIST": 0.9894999861717224,
                "loss/test/MNIST": 0.10167735069990158,
                "normalized_acc/test/MNIST": 0.9929754137992859
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7364085912704468,
                "loss/test/RenderedSST2": 0.5209874510765076,
                "normalized_acc/test/RenderedSST2": 0.954448401927948
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8629542887210846,
                "normalized_acc/test/avg": 0.9737119078636169
            }
        ]
    },
    "DTD__Flowers102": {
        "DTD": [
            {
                "acc/test/DTD": 0.63882976770401,
                "loss/test/DTD": 1.2588012218475342,
                "normalized_acc/test/DTD": 0.7708600163459778
            }
        ],
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.8120019435882568,
                "loss/test/Flowers102": 0.7864530682563782,
                "normalized_acc/test/Flowers102": 0.861753523349762
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7254158556461334,
                "normalized_acc/test/avg": 0.8163067698478699
            }
        ]
    },
    "DTD__PCAM": {
        "DTD": [
            {
                "acc/test/DTD": 0.5819149017333984,
                "loss/test/DTD": 1.409729242324829,
                "normalized_acc/test/DTD": 0.7021822929382324
            }
        ],
        "PCAM": [
            {
                "acc/test/PCAM": 0.82061767578125,
                "loss/test/PCAM": 0.3855201005935669,
                "normalized_acc/test/PCAM": 0.9249131679534912
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7012662887573242,
                "normalized_acc/test/avg": 0.8135477304458618
            }
        ]
    },
    "DTD__FER2013": {
        "DTD": [
            {
                "acc/test/DTD": 0.6260638236999512,
                "loss/test/DTD": 1.301343560218811,
                "normalized_acc/test/DTD": 0.7554556727409363
            }
        ],
        "FER2013": [
            {
                "acc/test/FER2013": 0.6734466552734375,
                "loss/test/FER2013": 0.9275739789009094,
                "normalized_acc/test/FER2013": 0.9134542942047119
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6497552394866943,
                "normalized_acc/test/avg": 0.8344549834728241
            }
        ]
    },
    "DTD__OxfordIIITPet": {
        "DTD": [
            {
                "acc/test/DTD": 0.6271276473999023,
                "loss/test/DTD": 1.2704178094863892,
                "normalized_acc/test/DTD": 0.7567393779754639
            }
        ],
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9384028315544128,
                "loss/test/OxfordIIITPet": 0.18558138608932495,
                "normalized_acc/test/OxfordIIITPet": 0.9873816967010498
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7827652394771576,
                "normalized_acc/test/avg": 0.8720605373382568
            }
        ]
    },
    "DTD__STL10": {
        "DTD": [
            {
                "acc/test/DTD": 0.6276595592498779,
                "loss/test/DTD": 1.3009289503097534,
                "normalized_acc/test/DTD": 0.7573812007904053
            }
        ],
        "STL10": [
            {
                "acc/test/STL10": 0.9898750185966492,
                "loss/test/STL10": 0.030755119398236275,
                "normalized_acc/test/STL10": 1.002024531364441
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8087672889232635,
                "normalized_acc/test/avg": 0.8797028660774231
            }
        ]
    },
    "DTD__CIFAR100": {
        "DTD": [
            {
                "acc/test/DTD": 0.6069148778915405,
                "loss/test/DTD": 1.4279783964157104,
                "normalized_acc/test/DTD": 0.7323490977287292
            }
        ],
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8373000025749207,
                "loss/test/CIFAR100": 0.6321022510528564,
                "normalized_acc/test/CIFAR100": 0.9379410743713379
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7221074402332306,
                "normalized_acc/test/avg": 0.8351450860500336
            }
        ]
    },
    "DTD__CIFAR10": {
        "DTD": [
            {
                "acc/test/DTD": 0.6058510541915894,
                "loss/test/DTD": 1.3636020421981812,
                "normalized_acc/test/DTD": 0.7310654520988464
            }
        ],
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9769999980926514,
                "loss/test/CIFAR10": 0.0761416032910347,
                "normalized_acc/test/CIFAR10": 0.9953137636184692
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7914255261421204,
                "normalized_acc/test/avg": 0.8631896078586578
            }
        ]
    },
    "DTD__Food101": {
        "DTD": [
            {
                "acc/test/DTD": 0.6223404407501221,
                "loss/test/DTD": 1.3189054727554321,
                "normalized_acc/test/DTD": 0.7509627938270569
            }
        ],
        "Food101": [
            {
                "acc/test/Food101": 0.9148514866828918,
                "loss/test/Food101": 0.3040890395641327,
                "normalized_acc/test/Food101": 1.0064482688903809
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.768595963716507,
                "normalized_acc/test/avg": 0.8787055313587189
            }
        ]
    },
    "DTD__FashionMNIST": {
        "DTD": [
            {
                "acc/test/DTD": 0.6074467897415161,
                "loss/test/DTD": 1.3543614149093628,
                "normalized_acc/test/DTD": 0.7329909801483154
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8999999761581421,
                "loss/test/FashionMNIST": 0.28520840406417847,
                "normalized_acc/test/FashionMNIST": 0.9453781247138977
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7537233829498291,
                "normalized_acc/test/avg": 0.8391845524311066
            }
        ]
    },
    "DTD__EMNIST": {
        "DTD": [
            {
                "acc/test/DTD": 0.6159574389457703,
                "loss/test/DTD": 1.3110826015472412,
                "normalized_acc/test/DTD": 0.7432605624198914
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9901999831199646,
                "loss/test/EMNIST": 0.11966973543167114,
                "normalized_acc/test/EMNIST": 0.9958764910697937
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8030787110328674,
                "normalized_acc/test/avg": 0.8695685267448425
            }
        ]
    },
    "DTD__KMNIST": {
        "DTD": [
            {
                "acc/test/DTD": 0.6186169981956482,
                "loss/test/DTD": 1.3166662454605103,
                "normalized_acc/test/DTD": 0.7464697957038879
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.5443000197410583,
                "loss/test/KMNIST": 1.6633232831954956,
                "normalized_acc/test/KMNIST": 0.5534316301345825
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.5814585089683533,
                "normalized_acc/test/avg": 0.6499507129192352
            }
        ]
    },
    "DTD__RenderedSST2": {
        "DTD": [
            {
                "acc/test/DTD": 0.6292552947998047,
                "loss/test/DTD": 1.247928500175476,
                "normalized_acc/test/DTD": 0.7593067288398743
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7517847418785095,
                "loss/test/RenderedSST2": 0.5151911377906799,
                "normalized_acc/test/RenderedSST2": 0.9743772149085999
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6905200183391571,
                "normalized_acc/test/avg": 0.8668419718742371
            }
        ]
    },
    "Flowers102__PCAM": {
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.7505285143852234,
                "loss/test/Flowers102": 0.9794042706489563,
                "normalized_acc/test/Flowers102": 0.796513557434082
            }
        ],
        "PCAM": [
            {
                "acc/test/PCAM": 0.801849365234375,
                "loss/test/PCAM": 0.4151570200920105,
                "normalized_acc/test/PCAM": 0.9037594795227051
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7761889398097992,
                "normalized_acc/test/avg": 0.8501365184783936
            }
        ]
    },
    "Flowers102__FER2013": {
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.7967149019241333,
                "loss/test/Flowers102": 0.8195715546607971,
                "normalized_acc/test/Flowers102": 0.8455297946929932
            }
        ],
        "FER2013": [
            {
                "acc/test/FER2013": 0.6780440211296082,
                "loss/test/FER2013": 0.9109427332878113,
                "normalized_acc/test/FER2013": 0.9196900725364685
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7373794615268707,
                "normalized_acc/test/avg": 0.8826099336147308
            }
        ]
    },
    "Flowers102__OxfordIIITPet": {
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.7980159521102905,
                "loss/test/Flowers102": 0.844408392906189,
                "normalized_acc/test/Flowers102": 0.8469105958938599
            }
        ],
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9378577470779419,
                "loss/test/OxfordIIITPet": 0.18297438323497772,
                "normalized_acc/test/OxfordIIITPet": 0.9868081212043762
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8679368495941162,
                "normalized_acc/test/avg": 0.916859358549118
            }
        ]
    },
    "Flowers102__STL10": {
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.7986664772033691,
                "loss/test/Flowers102": 0.8541287183761597,
                "normalized_acc/test/Flowers102": 0.8476009964942932
            }
        ],
        "STL10": [
            {
                "acc/test/STL10": 0.9893749952316284,
                "loss/test/STL10": 0.03544481843709946,
                "normalized_acc/test/STL10": 1.0015183687210083
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8940207362174988,
                "normalized_acc/test/avg": 0.9245596826076508
            }
        ]
    },
    "Flowers102__CIFAR100": {
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.7799642086029053,
                "loss/test/Flowers102": 1.0325342416763306,
                "normalized_acc/test/Flowers102": 0.8277528285980225
            }
        ],
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8427000045776367,
                "loss/test/CIFAR100": 0.5776476860046387,
                "normalized_acc/test/CIFAR100": 0.9439901113510132
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.811332106590271,
                "normalized_acc/test/avg": 0.8858714699745178
            }
        ]
    },
    "Flowers102__CIFAR10": {
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.782728910446167,
                "loss/test/Flowers102": 0.9203331470489502,
                "normalized_acc/test/Flowers102": 0.8306869268417358
            }
        ],
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9771000146865845,
                "loss/test/CIFAR10": 0.07488671690225601,
                "normalized_acc/test/CIFAR10": 0.9954156875610352
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8799144625663757,
                "normalized_acc/test/avg": 0.9130513072013855
            }
        ]
    },
    "Flowers102__Food101": {
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.796389639377594,
                "loss/test/Flowers102": 0.8554310202598572,
                "normalized_acc/test/Flowers102": 0.8451846241950989
            }
        ],
        "Food101": [
            {
                "acc/test/Food101": 0.9180594086647034,
                "loss/test/Food101": 0.29200688004493713,
                "normalized_acc/test/Food101": 1.0099773406982422
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8572245240211487,
                "normalized_acc/test/avg": 0.9275809824466705
            }
        ]
    },
    "Flowers102__FashionMNIST": {
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.7890713810920715,
                "loss/test/Flowers102": 0.8815066814422607,
                "normalized_acc/test/Flowers102": 0.8374179601669312
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8984000086784363,
                "loss/test/FashionMNIST": 0.28893330693244934,
                "normalized_acc/test/FashionMNIST": 0.943697452545166
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8437356948852539,
                "normalized_acc/test/avg": 0.8905577063560486
            }
        ]
    },
    "Flowers102__EMNIST": {
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.7903724312782288,
                "loss/test/Flowers102": 0.8796462416648865,
                "normalized_acc/test/Flowers102": 0.8387987613677979
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9907000064849854,
                "loss/test/EMNIST": 0.139799103140831,
                "normalized_acc/test/EMNIST": 0.9963793754577637
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8905362188816071,
                "normalized_acc/test/avg": 0.9175890684127808
            }
        ]
    },
    "Flowers102__KMNIST": {
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.7942754626274109,
                "loss/test/Flowers102": 0.817182719707489,
                "normalized_acc/test/Flowers102": 0.8429409265518188
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.5167999863624573,
                "loss/test/KMNIST": 1.7202659845352173,
                "normalized_acc/test/KMNIST": 0.5254702568054199
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6555377244949341,
                "normalized_acc/test/avg": 0.6842055916786194
            }
        ]
    },
    "Flowers102__RenderedSST2": {
        "Flowers102": [
            {
                "acc/test/Flowers102": 0.8001301288604736,
                "loss/test/Flowers102": 0.78695148229599,
                "normalized_acc/test/Flowers102": 0.8491542935371399
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7457441091537476,
                "loss/test/RenderedSST2": 0.5099231600761414,
                "normalized_acc/test/RenderedSST2": 0.9665480256080627
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7729371190071106,
                "normalized_acc/test/avg": 0.9078511595726013
            }
        ]
    },
    "PCAM__FER2013": {
        "PCAM": [
            {
                "acc/test/PCAM": 0.80120849609375,
                "loss/test/PCAM": 0.41316238045692444,
                "normalized_acc/test/PCAM": 0.9030371904373169
            }
        ],
        "FER2013": [
            {
                "acc/test/FER2013": 0.6710783243179321,
                "loss/test/FER2013": 0.9189254641532898,
                "normalized_acc/test/FER2013": 0.9102419018745422
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7361434102058411,
                "normalized_acc/test/avg": 0.9066395461559296
            }
        ]
    },
    "PCAM__OxfordIIITPet": {
        "PCAM": [
            {
                "acc/test/PCAM": 0.79254150390625,
                "loss/test/PCAM": 0.4268867075443268,
                "normalized_acc/test/PCAM": 0.8932686448097229
            }
        ],
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9258653521537781,
                "loss/test/OxfordIIITPet": 0.2171182483434677,
                "normalized_acc/test/OxfordIIITPet": 0.974189817905426
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.859203428030014,
                "normalized_acc/test/avg": 0.9337292313575745
            }
        ]
    },
    "PCAM__STL10": {
        "PCAM": [
            {
                "acc/test/PCAM": 0.77581787109375,
                "loss/test/PCAM": 0.4593649208545685,
                "normalized_acc/test/PCAM": 0.8744195699691772
            }
        ],
        "STL10": [
            {
                "acc/test/STL10": 0.9862499833106995,
                "loss/test/STL10": 0.04610828310251236,
                "normalized_acc/test/STL10": 0.9983550310134888
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8810339272022247,
                "normalized_acc/test/avg": 0.936387300491333
            }
        ]
    },
    "PCAM__CIFAR100": {
        "PCAM": [
            {
                "acc/test/PCAM": 0.787506103515625,
                "loss/test/PCAM": 0.43891388177871704,
                "normalized_acc/test/PCAM": 0.8875933289527893
            }
        ],
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8116999864578247,
                "loss/test/CIFAR100": 0.6612322330474854,
                "normalized_acc/test/CIFAR100": 0.9092640280723572
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7996030449867249,
                "normalized_acc/test/avg": 0.8984286785125732
            }
        ]
    },
    "PCAM__CIFAR10": {
        "PCAM": [
            {
                "acc/test/PCAM": 0.78814697265625,
                "loss/test/PCAM": 0.43470442295074463,
                "normalized_acc/test/PCAM": 0.8883156180381775
            }
        ],
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9717000126838684,
                "loss/test/CIFAR10": 0.09393909573554993,
                "normalized_acc/test/CIFAR10": 0.9899144768714905
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8799234926700592,
                "normalized_acc/test/avg": 0.939115047454834
            }
        ]
    },
    "PCAM__Food101": {
        "PCAM": [
            {
                "acc/test/PCAM": 0.788604736328125,
                "loss/test/PCAM": 0.43315252661705017,
                "normalized_acc/test/PCAM": 0.8888315558433533
            }
        ],
        "Food101": [
            {
                "acc/test/Food101": 0.8973861336708069,
                "loss/test/Food101": 0.3586932122707367,
                "normalized_acc/test/Food101": 0.9872342348098755
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8429954349994659,
                "normalized_acc/test/avg": 0.9380328953266144
            }
        ]
    },
    "PCAM__FashionMNIST": {
        "PCAM": [
            {
                "acc/test/PCAM": 0.78289794921875,
                "loss/test/PCAM": 0.443469762802124,
                "normalized_acc/test/PCAM": 0.8823994994163513
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.887499988079071,
                "loss/test/FashionMNIST": 0.3225324749946594,
                "normalized_acc/test/FashionMNIST": 0.9322478771209717
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8351989686489105,
                "normalized_acc/test/avg": 0.9073236882686615
            }
        ]
    },
    "PCAM__EMNIST": {
        "PCAM": [
            {
                "acc/test/PCAM": 0.796722412109375,
                "loss/test/PCAM": 0.42202228307724,
                "normalized_acc/test/PCAM": 0.8979809284210205
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.989300012588501,
                "loss/test/EMNIST": 0.1936778873205185,
                "normalized_acc/test/EMNIST": 0.9949713349342346
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.893011212348938,
                "normalized_acc/test/avg": 0.9464761316776276
            }
        ]
    },
    "PCAM__KMNIST": {
        "PCAM": [
            {
                "acc/test/PCAM": 0.775726318359375,
                "loss/test/PCAM": 0.4530734121799469,
                "normalized_acc/test/PCAM": 0.874316394329071
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.40149998664855957,
                "loss/test/KMNIST": 1.9139790534973145,
                "normalized_acc/test/KMNIST": 0.4082358777523041
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.5886131525039673,
                "normalized_acc/test/avg": 0.6412761360406876
            }
        ]
    },
    "PCAM__RenderedSST2": {
        "PCAM": [
            {
                "acc/test/PCAM": 0.786102294921875,
                "loss/test/PCAM": 0.4418080747127533,
                "normalized_acc/test/PCAM": 0.8860110640525818
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7413508892059326,
                "loss/test/RenderedSST2": 0.524609386920929,
                "normalized_acc/test/RenderedSST2": 0.9608540534973145
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7637265920639038,
                "normalized_acc/test/avg": 0.9234325587749481
            }
        ]
    },
    "FER2013__OxfordIIITPet": {
        "FER2013": [
            {
                "acc/test/FER2013": 0.6788799166679382,
                "loss/test/FER2013": 0.9096030592918396,
                "normalized_acc/test/FER2013": 0.920823872089386
            }
        ],
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9364949464797974,
                "loss/test/OxfordIIITPet": 0.18766246736049652,
                "normalized_acc/test/OxfordIIITPet": 0.9853742122650146
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8076874315738678,
                "normalized_acc/test/avg": 0.9530990421772003
            }
        ]
    },
    "FER2013__STL10": {
        "FER2013": [
            {
                "acc/test/FER2013": 0.6719141602516174,
                "loss/test/FER2013": 0.9177708625793457,
                "normalized_acc/test/FER2013": 0.9113756418228149
            }
        ],
        "STL10": [
            {
                "acc/test/STL10": 0.9890000224113464,
                "loss/test/STL10": 0.0364237017929554,
                "normalized_acc/test/STL10": 1.0011388063430786
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8304570913314819,
                "normalized_acc/test/avg": 0.9562572240829468
            }
        ]
    },
    "FER2013__CIFAR100": {
        "FER2013": [
            {
                "acc/test/FER2013": 0.6595152020454407,
                "loss/test/FER2013": 0.9538275599479675,
                "normalized_acc/test/FER2013": 0.8945578336715698
            }
        ],
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.835099995136261,
                "loss/test/CIFAR100": 0.6048473119735718,
                "normalized_acc/test/CIFAR100": 0.9354766011238098
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7473075985908508,
                "normalized_acc/test/avg": 0.9150172173976898
            }
        ]
    },
    "FER2013__CIFAR10": {
        "FER2013": [
            {
                "acc/test/FER2013": 0.6549177765846252,
                "loss/test/FER2013": 0.9567288756370544,
                "normalized_acc/test/FER2013": 0.8883219361305237
            }
        ],
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9732000231742859,
                "loss/test/CIFAR10": 0.0857381597161293,
                "normalized_acc/test/CIFAR10": 0.9914425611495972
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8140588998794556,
                "normalized_acc/test/avg": 0.9398822486400604
            }
        ]
    },
    "FER2013__Food101": {
        "FER2013": [
            {
                "acc/test/FER2013": 0.6727500557899475,
                "loss/test/FER2013": 0.9163231253623962,
                "normalized_acc/test/FER2013": 0.9125094413757324
            }
        ],
        "Food101": [
            {
                "acc/test/Food101": 0.914336621761322,
                "loss/test/Food101": 0.3032289147377014,
                "normalized_acc/test/Food101": 1.0058817863464355
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7935433387756348,
                "normalized_acc/test/avg": 0.959195613861084
            }
        ]
    },
    "FER2013__FashionMNIST": {
        "FER2013": [
            {
                "acc/test/FER2013": 0.6471161842346191,
                "loss/test/FER2013": 0.9689472317695618,
                "normalized_acc/test/FER2013": 0.8777399659156799
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8970999717712402,
                "loss/test/FashionMNIST": 0.2992737889289856,
                "normalized_acc/test/FashionMNIST": 0.9423319101333618
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7721080780029297,
                "normalized_acc/test/avg": 0.9100359380245209
            }
        ]
    },
    "FER2013__EMNIST": {
        "FER2013": [
            {
                "acc/test/FER2013": 0.6460016965866089,
                "loss/test/FER2013": 0.9876229763031006,
                "normalized_acc/test/FER2013": 0.8762283325195312
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9901999831199646,
                "loss/test/EMNIST": 0.12606465816497803,
                "normalized_acc/test/EMNIST": 0.9958764910697937
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8181008398532867,
                "normalized_acc/test/avg": 0.9360524117946625
            }
        ]
    },
    "FER2013__KMNIST": {
        "FER2013": [
            {
                "acc/test/FER2013": 0.6571468114852905,
                "loss/test/FER2013": 0.9513845443725586,
                "normalized_acc/test/FER2013": 0.8913453817367554
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.5419999957084656,
                "loss/test/KMNIST": 1.6490650177001953,
                "normalized_acc/test/KMNIST": 0.5510930418968201
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.599573403596878,
                "normalized_acc/test/avg": 0.7212192118167877
            }
        ]
    },
    "FER2013__RenderedSST2": {
        "FER2013": [
            {
                "acc/test/FER2013": 0.6695458292961121,
                "loss/test/FER2013": 0.9280188083648682,
                "normalized_acc/test/FER2013": 0.9081632494926453
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7281713485717773,
                "loss/test/RenderedSST2": 0.5602772235870361,
                "normalized_acc/test/RenderedSST2": 0.9437722563743591
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6988585889339447,
                "normalized_acc/test/avg": 0.9259677529335022
            }
        ]
    },
    "OxfordIIITPet__STL10": {
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9397656321525574,
                "loss/test/OxfordIIITPet": 0.1823994517326355,
                "normalized_acc/test/OxfordIIITPet": 0.9888156056404114
            }
        ],
        "STL10": [
            {
                "acc/test/STL10": 0.9887499809265137,
                "loss/test/STL10": 0.040102336555719376,
                "normalized_acc/test/STL10": 1.0008857250213623
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9642578065395355,
                "normalized_acc/test/avg": 0.9948506653308868
            }
        ]
    },
    "OxfordIIITPet__CIFAR100": {
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9329517483711243,
                "loss/test/OxfordIIITPet": 0.19972722232341766,
                "normalized_acc/test/OxfordIIITPet": 0.9816460609436035
            }
        ],
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8424000144004822,
                "loss/test/CIFAR100": 0.5899348855018616,
                "normalized_acc/test/CIFAR100": 0.9436540603637695
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8876758813858032,
                "normalized_acc/test/avg": 0.9626500606536865
            }
        ]
    },
    "OxfordIIITPet__CIFAR10": {
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9313164353370667,
                "loss/test/OxfordIIITPet": 0.20405539870262146,
                "normalized_acc/test/OxfordIIITPet": 0.9799253940582275
            }
        ],
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9769999980926514,
                "loss/test/CIFAR10": 0.07623329013586044,
                "normalized_acc/test/CIFAR10": 0.9953137636184692
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.954158216714859,
                "normalized_acc/test/avg": 0.9876195788383484
            }
        ]
    },
    "OxfordIIITPet__Food101": {
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9343145489692688,
                "loss/test/OxfordIIITPet": 0.1902792900800705,
                "normalized_acc/test/OxfordIIITPet": 0.9830800294876099
            }
        ],
        "Food101": [
            {
                "acc/test/Food101": 0.9165940880775452,
                "loss/test/Food101": 0.29316335916519165,
                "normalized_acc/test/Food101": 1.008365273475647
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.925454318523407,
                "normalized_acc/test/avg": 0.9957226514816284
            }
        ]
    },
    "OxfordIIITPet__FashionMNIST": {
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9315890073776245,
                "loss/test/OxfordIIITPet": 0.19875694811344147,
                "normalized_acc/test/OxfordIIITPet": 0.9802122116088867
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8952000141143799,
                "loss/test/FashionMNIST": 0.29752808809280396,
                "normalized_acc/test/FashionMNIST": 0.9403361082077026
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9133945107460022,
                "normalized_acc/test/avg": 0.9602741599082947
            }
        ]
    },
    "OxfordIIITPet__EMNIST": {
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9332243204116821,
                "loss/test/OxfordIIITPet": 0.19130758941173553,
                "normalized_acc/test/OxfordIIITPet": 0.9819328784942627
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.989799976348877,
                "loss/test/EMNIST": 0.13604293763637543,
                "normalized_acc/test/EMNIST": 0.9954741597175598
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9615121483802795,
                "normalized_acc/test/avg": 0.9887035191059113
            }
        ]
    },
    "OxfordIIITPet__KMNIST": {
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9299536943435669,
                "loss/test/OxfordIIITPet": 0.19661495089530945,
                "normalized_acc/test/OxfordIIITPet": 0.9784915447235107
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.5078999996185303,
                "loss/test/KMNIST": 1.7472957372665405,
                "normalized_acc/test/KMNIST": 0.5164209604263306
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7189268469810486,
                "normalized_acc/test/avg": 0.7474562525749207
            }
        ]
    },
    "OxfordIIITPet__RenderedSST2": {
        "OxfordIIITPet": [
            {
                "acc/test/OxfordIIITPet": 0.9386754035949707,
                "loss/test/OxfordIIITPet": 0.18378902971744537,
                "normalized_acc/test/OxfordIIITPet": 0.9876684546470642
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7440966367721558,
                "loss/test/RenderedSST2": 0.5099822282791138,
                "normalized_acc/test/RenderedSST2": 0.9644127488136292
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8413860201835632,
                "normalized_acc/test/avg": 0.9760406017303467
            }
        ]
    },
    "STL10__CIFAR100": {
        "STL10": [
            {
                "acc/test/STL10": 0.987375020980835,
                "loss/test/STL10": 0.03931330144405365,
                "normalized_acc/test/STL10": 0.9994938969612122
            }
        ],
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8353999853134155,
                "loss/test/CIFAR100": 0.6077017784118652,
                "normalized_acc/test/CIFAR100": 0.9358126521110535
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9113875031471252,
                "normalized_acc/test/avg": 0.9676532745361328
            }
        ]
    },
    "STL10__CIFAR10": {
        "STL10": [
            {
                "acc/test/STL10": 0.9837499856948853,
                "loss/test/STL10": 0.05262705311179161,
                "normalized_acc/test/STL10": 0.99582439661026
            }
        ],
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9749000072479248,
                "loss/test/CIFAR10": 0.08664517104625702,
                "normalized_acc/test/CIFAR10": 0.9931744337081909
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.979324996471405,
                "normalized_acc/test/avg": 0.9944994151592255
            }
        ]
    },
    "STL10__Food101": {
        "STL10": [
            {
                "acc/test/STL10": 0.9892500042915344,
                "loss/test/STL10": 0.0374726876616478,
                "normalized_acc/test/STL10": 1.001391887664795
            }
        ],
        "Food101": [
            {
                "acc/test/Food101": 0.9150099158287048,
                "loss/test/Food101": 0.29611435532569885,
                "normalized_acc/test/Food101": 1.006622552871704
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9521299600601196,
                "normalized_acc/test/avg": 1.0040072202682495
            }
        ]
    },
    "STL10__FashionMNIST": {
        "STL10": [
            {
                "acc/test/STL10": 0.9862499833106995,
                "loss/test/STL10": 0.0438084714114666,
                "normalized_acc/test/STL10": 0.9983550310134888
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8928999900817871,
                "loss/test/FashionMNIST": 0.30487146973609924,
                "normalized_acc/test/FashionMNIST": 0.9379201531410217
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9395749866962433,
                "normalized_acc/test/avg": 0.9681375920772552
            }
        ]
    },
    "STL10__EMNIST": {
        "STL10": [
            {
                "acc/test/STL10": 0.987625002861023,
                "loss/test/STL10": 0.03936511278152466,
                "normalized_acc/test/STL10": 0.9997469782829285
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9894999861717224,
                "loss/test/EMNIST": 0.1500406712293625,
                "normalized_acc/test/EMNIST": 0.9951724410057068
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9885624945163727,
                "normalized_acc/test/avg": 0.9974597096443176
            }
        ]
    },
    "STL10__KMNIST": {
        "STL10": [
            {
                "acc/test/STL10": 0.987625002861023,
                "loss/test/STL10": 0.039789095520973206,
                "normalized_acc/test/STL10": 0.9997469782829285
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.4781000018119812,
                "loss/test/KMNIST": 1.8072335720062256,
                "normalized_acc/test/KMNIST": 0.4861209988594055
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7328625023365021,
                "normalized_acc/test/avg": 0.742933988571167
            }
        ]
    },
    "STL10__RenderedSST2": {
        "STL10": [
            {
                "acc/test/STL10": 0.9896249771118164,
                "loss/test/STL10": 0.03467218950390816,
                "normalized_acc/test/STL10": 1.0017714500427246
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7473915219306946,
                "loss/test/RenderedSST2": 0.5222940444946289,
                "normalized_acc/test/RenderedSST2": 0.9686832427978516
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8685082495212555,
                "normalized_acc/test/avg": 0.9852273464202881
            }
        ]
    },
    "CIFAR100__CIFAR10": {
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8445000052452087,
                "loss/test/CIFAR100": 0.5477591156959534,
                "normalized_acc/test/CIFAR100": 0.9460064768791199
            }
        ],
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9781000018119812,
                "loss/test/CIFAR10": 0.07038766145706177,
                "normalized_acc/test/CIFAR10": 0.9964343905448914
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.911300003528595,
                "normalized_acc/test/avg": 0.9712204337120056
            }
        ]
    },
    "CIFAR100__Food101": {
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8360000252723694,
                "loss/test/CIFAR100": 0.6069383025169373,
                "normalized_acc/test/CIFAR100": 0.9364848136901855
            }
        ],
        "Food101": [
            {
                "acc/test/Food101": 0.9049900770187378,
                "loss/test/Food101": 0.3380206823348999,
                "normalized_acc/test/Food101": 0.9955995082855225
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8704950511455536,
                "normalized_acc/test/avg": 0.966042160987854
            }
        ]
    },
    "CIFAR100__FashionMNIST": {
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8251000046730042,
                "loss/test/CIFAR100": 0.6280784010887146,
                "normalized_acc/test/CIFAR100": 0.9242746829986572
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8971999883651733,
                "loss/test/FashionMNIST": 0.30291616916656494,
                "normalized_acc/test/FashionMNIST": 0.942436933517456
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8611499965190887,
                "normalized_acc/test/avg": 0.9333558082580566
            }
        ]
    },
    "CIFAR100__EMNIST": {
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.828000009059906,
                "loss/test/CIFAR100": 0.6361860632896423,
                "normalized_acc/test/CIFAR100": 0.9275232553482056
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9889000058174133,
                "loss/test/EMNIST": 0.1306670904159546,
                "normalized_acc/test/EMNIST": 0.9945690631866455
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9084500074386597,
                "normalized_acc/test/avg": 0.9610461592674255
            }
        ]
    },
    "CIFAR100__KMNIST": {
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8169999718666077,
                "loss/test/CIFAR100": 0.6780632138252258,
                "normalized_acc/test/CIFAR100": 0.9152010083198547
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.5105999708175659,
                "loss/test/KMNIST": 1.6845170259475708,
                "normalized_acc/test/KMNIST": 0.5191662311553955
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6637999713420868,
                "normalized_acc/test/avg": 0.7171836197376251
            }
        ]
    },
    "CIFAR100__RenderedSST2": {
        "CIFAR100": [
            {
                "acc/test/CIFAR100": 0.8420000076293945,
                "loss/test/CIFAR100": 0.5657895803451538,
                "normalized_acc/test/CIFAR100": 0.9432060122489929
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7215815782546997,
                "loss/test/RenderedSST2": 0.5595564246177673,
                "normalized_acc/test/RenderedSST2": 0.9352313280105591
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7817907929420471,
                "normalized_acc/test/avg": 0.939218670129776
            }
        ]
    },
    "CIFAR10__Food101": {
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9761999845504761,
                "loss/test/CIFAR10": 0.07862011343240738,
                "normalized_acc/test/CIFAR10": 0.9944987893104553
            }
        ],
        "Food101": [
            {
                "acc/test/Food101": 0.9063762426376343,
                "loss/test/Food101": 0.3256584405899048,
                "normalized_acc/test/Food101": 0.997124433517456
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9412881135940552,
                "normalized_acc/test/avg": 0.9958116114139557
            }
        ]
    },
    "CIFAR10__FashionMNIST": {
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9725000262260437,
                "loss/test/CIFAR10": 0.08936332166194916,
                "normalized_acc/test/CIFAR10": 0.9907294511795044
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8903999924659729,
                "loss/test/FashionMNIST": 0.3154812753200531,
                "normalized_acc/test/FashionMNIST": 0.9352940917015076
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9314500093460083,
                "normalized_acc/test/avg": 0.963011771440506
            }
        ]
    },
    "CIFAR10__EMNIST": {
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9728999733924866,
                "loss/test/CIFAR10": 0.08392152935266495,
                "normalized_acc/test/CIFAR10": 0.991136908531189
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9883999824523926,
                "loss/test/EMNIST": 0.17257040739059448,
                "normalized_acc/test/EMNIST": 0.9940661787986755
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9806499779224396,
                "normalized_acc/test/avg": 0.9926015436649323
            }
        ]
    },
    "CIFAR10__KMNIST": {
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9703999757766724,
                "loss/test/CIFAR10": 0.09422648698091507,
                "normalized_acc/test/CIFAR10": 0.9885900616645813
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.40880000591278076,
                "loss/test/KMNIST": 1.8335189819335938,
                "normalized_acc/test/KMNIST": 0.4156583547592163
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6895999908447266,
                "normalized_acc/test/avg": 0.7021242082118988
            }
        ]
    },
    "CIFAR10__RenderedSST2": {
        "CIFAR10": [
            {
                "acc/test/CIFAR10": 0.9785000085830688,
                "loss/test/CIFAR10": 0.06921229511499405,
                "normalized_acc/test/CIFAR10": 0.9968419075012207
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7424492239952087,
                "loss/test/RenderedSST2": 0.5181596279144287,
                "normalized_acc/test/RenderedSST2": 0.9622775912284851
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8604746162891388,
                "normalized_acc/test/avg": 0.9795597493648529
            }
        ]
    },
    "Food101__FashionMNIST": {
        "Food101": [
            {
                "acc/test/Food101": 0.9087525010108948,
                "loss/test/Food101": 0.31836292147636414,
                "normalized_acc/test/Food101": 0.9997386336326599
            }
        ],
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8937000036239624,
                "loss/test/FashionMNIST": 0.30382317304611206,
                "normalized_acc/test/FashionMNIST": 0.9387604594230652
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9012262523174286,
                "normalized_acc/test/avg": 0.9692495465278625
            }
        ]
    },
    "Food101__EMNIST": {
        "Food101": [
            {
                "acc/test/Food101": 0.9105742573738098,
                "loss/test/Food101": 0.3114231824874878,
                "normalized_acc/test/Food101": 1.0017428398132324
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9894000291824341,
                "loss/test/EMNIST": 0.13697096705436707,
                "normalized_acc/test/EMNIST": 0.9950719475746155
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.949987143278122,
                "normalized_acc/test/avg": 0.998407393693924
            }
        ]
    },
    "Food101__KMNIST": {
        "Food101": [
            {
                "acc/test/Food101": 0.9087920784950256,
                "loss/test/Food101": 0.31646424531936646,
                "normalized_acc/test/Food101": 0.999782145023346
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.4887000024318695,
                "loss/test/KMNIST": 1.7750699520111084,
                "normalized_acc/test/KMNIST": 0.4968988299369812
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6987460404634476,
                "normalized_acc/test/avg": 0.7483404874801636
            }
        ]
    },
    "Food101__RenderedSST2": {
        "Food101": [
            {
                "acc/test/Food101": 0.9158415794372559,
                "loss/test/Food101": 0.29230546951293945,
                "normalized_acc/test/Food101": 1.0075374841690063
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7451949715614319,
                "loss/test/RenderedSST2": 0.519723653793335,
                "normalized_acc/test/RenderedSST2": 0.9658362865447998
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8305182754993439,
                "normalized_acc/test/avg": 0.9866868853569031
            }
        ]
    },
    "FashionMNIST__EMNIST": {
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8870000243186951,
                "loss/test/FashionMNIST": 0.32984524965286255,
                "normalized_acc/test/FashionMNIST": 0.9317227005958557
            }
        ],
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9873999953269958,
                "loss/test/EMNIST": 0.18129652738571167,
                "normalized_acc/test/EMNIST": 0.9930604100227356
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.9372000098228455,
                "normalized_acc/test/avg": 0.9623915553092957
            }
        ]
    },
    "FashionMNIST__KMNIST": {
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8701000213623047,
                "loss/test/FashionMNIST": 0.3862423300743103,
                "normalized_acc/test/FashionMNIST": 0.9139705896377563
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.4018000066280365,
                "loss/test/KMNIST": 1.8206287622451782,
                "normalized_acc/test/KMNIST": 0.4085409343242645
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6359500139951706,
                "normalized_acc/test/avg": 0.6612557619810104
            }
        ]
    },
    "FashionMNIST__RenderedSST2": {
        "FashionMNIST": [
            {
                "acc/test/FashionMNIST": 0.8939999938011169,
                "loss/test/FashionMNIST": 0.2988140881061554,
                "normalized_acc/test/FashionMNIST": 0.9390755891799927
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7369577288627625,
                "loss/test/RenderedSST2": 0.5313600301742554,
                "normalized_acc/test/RenderedSST2": 0.9551601409912109
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8154788613319397,
                "normalized_acc/test/avg": 0.9471178650856018
            }
        ]
    },
    "EMNIST__KMNIST": {
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9879000186920166,
                "loss/test/EMNIST": 0.13584963977336884,
                "normalized_acc/test/EMNIST": 0.9935632944107056
            }
        ],
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.4643999934196472,
                "loss/test/KMNIST": 1.7230578660964966,
                "normalized_acc/test/KMNIST": 0.4721911549568176
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.7261500060558319,
                "normalized_acc/test/avg": 0.7328772246837616
            }
        ]
    },
    "EMNIST__RenderedSST2": {
        "EMNIST": [
            {
                "acc/test/EMNIST": 0.9912999868392944,
                "loss/test/EMNIST": 0.13001678884029388,
                "normalized_acc/test/EMNIST": 0.996982753276825
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.722679853439331,
                "loss/test/RenderedSST2": 0.5541151762008667,
                "normalized_acc/test/RenderedSST2": 0.936654806137085
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.8569899201393127,
                "normalized_acc/test/avg": 0.966818779706955
            }
        ]
    },
    "KMNIST__RenderedSST2": {
        "KMNIST": [
            {
                "acc/test/KMNIST": 0.49149999022483826,
                "loss/test/KMNIST": 1.7809804677963257,
                "normalized_acc/test/KMNIST": 0.49974578619003296
            }
        ],
        "RenderedSST2": [
            {
                "acc/test/RenderedSST2": 0.7358593940734863,
                "loss/test/RenderedSST2": 0.5421028137207031,
                "normalized_acc/test/RenderedSST2": 0.9537366032600403
            }
        ],
        "avg": [
            {
                "acc/test/avg": 0.6136796921491623,
                "normalized_acc/test/avg": 0.7267411947250366
            }
        ]
    }
}