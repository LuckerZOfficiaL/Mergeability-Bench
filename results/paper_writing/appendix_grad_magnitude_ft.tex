\section{Gradient Magnitude Regularization for Merge-Aware Finetuning}
\label{app:grad_magnitude_ft}

This appendix provides details on our proof-of-concept experiment investigating whether finetuning procedures informed by mergeability metrics can produce more mergeable models.

\subsection{Motivation}

Our coefficient analysis identified gradient-based metrics as important predictors of mergeability. In particular, gradient distance between task-specific models correlates with post-merge performance degradation. This suggests that models whose gradients are more aligned---or equivalently, whose parameter updates from the pretrained initialization remain similar in direction and magnitude---may be more compatible for merging.

One simple way to encourage such alignment is to regularize the magnitude of parameter updates during finetuning. By penalizing large deviations from the pretrained weights, we bias all task-specific models to remain close to the shared initialization. This keeps the models within a similar region of the loss landscape, which naturally promotes gradient alignment and reduces gradient distance between any pair of finetuned models.

\subsection{Method}

We augment the standard cross-entropy finetuning objective with an $L_2$ penalty on the parameter updates:
\begin{equation}
    \mathcal{L}_{\text{total}} = \mathcal{L}_{\text{CE}} + \lambda \| \theta - \theta_{\text{pretrained}} \|_2^2
\end{equation}
where $\theta$ denotes the current model parameters, $\theta_{\text{pretrained}}$ is the pretrained initialization, and $\lambda$ controls the regularization strength.

This formulation is equivalent to $L_2$ regularization toward the pretrained weights rather than toward zero. It encourages the finetuned model to stay close to the pretrained solution while still adapting to the downstream task.

\subsection{Experimental Setup}

We finetune ViT-B/16 models on all 20 tasks in our benchmark using the same hyperparameters as the baseline (learning rate, epochs, batch size), with the addition of the gradient magnitude penalty. We evaluate three regularization strengths spanning three orders of magnitude: $\lambda \in \{0.001, 0.1, 1\}$.

After finetuning, we merge all pairwise combinations using four merging methods: Weight Averaging, Arithmetic merging, Task Singular Vectors (TSV), and Isotropic Merging. We report the average normalized accuracy across all 190 task pairs.

\subsection{Results}

Table~\ref{tab:grad_mag_results} presents the results comparing baseline finetuning against gradient magnitude regularization with different $\lambda$ values.

\begin{table}[h]
\centering
\caption{Effect of gradient magnitude regularization on post-merge performance. We report average normalized accuracy (\%) across all 190 task pairs. $\Delta$ indicates the improvement over baseline finetuning.}
\label{tab:grad_mag_results}
\begin{tabular}{lccccccc}
\toprule
\textbf{Method} & \textbf{Baseline} & \textbf{$\lambda=0.001$} & \textbf{$\Delta$} & \textbf{$\lambda=0.1$} & \textbf{$\Delta$} & \textbf{$\lambda=1$} & \textbf{$\Delta$} \\
\midrule
Weight Averaging & 95.86 & 96.11 & +0.25 & 96.23 & +0.37 & 96.47 & +0.62 \\
Arithmetic & 91.02 & 91.16 & +0.14 & 91.16 & +0.14 & 91.74 & +0.72 \\
Task Singular Vectors & 98.18 & 98.52 & +0.33 & 98.51 & +0.32 & 98.57 & +0.39 \\
Isotropic Merging & 88.40 & 88.54 & +0.15 & 88.58 & +0.19 & 88.88 & +0.48 \\
\midrule
\textbf{Average} & 93.36 & 93.58 & +0.22 & 93.62 & +0.25 & 93.92 & \textbf{+0.55} \\
\bottomrule
\end{tabular}
\end{table}

\subsection{Discussion}

The results demonstrate that gradient magnitude regularization consistently improves mergeability across all four merging methods. Key observations include:

\paragraph{Consistent improvements.} All three $\lambda$ values yield positive improvements for every merging method. The average gains increase monotonically with regularization strength: +0.22\% ($\lambda=0.001$), +0.25\% ($\lambda=0.1$), and +0.55\% ($\lambda=1$). While modest in absolute terms, the consistency across methods and the clear trend with $\lambda$ suggest that the regularization is targeting a fundamental property relevant to mergeability.

\paragraph{Stronger regularization yields larger gains.} The best results are achieved with $\lambda=1$, the strongest regularization tested. This indicates that keeping finetuned models closer to the pretrained initialization provides meaningful benefits for mergeability. The monotonic improvement across three orders of magnitude of $\lambda$ suggests that even stronger regularization might yield further gains, though this would need to be balanced against potential degradation in single-task performance.

\paragraph{Method-specific effects.} At $\lambda=1$, Arithmetic merging shows the largest improvement (+0.72\%), followed by Weight Averaging (+0.62\%), Isotropic Merging (+0.48\%), and TSV (+0.39\%). Interestingly, this ranking differs from the weaker regularization settings, where TSV and Weight Averaging benefited most. This suggests that different merging methods may have different optimal regularization strengths, opening avenues for method-specific merge-aware finetuning.

\paragraph{Limitations.} This experiment serves as a proof of concept rather than a comprehensive solution. The improvements, while consistent, are modest. We did not evaluate the impact on single-task performance, which may degrade with stronger regularization. More sophisticated regularization strategies that directly target the identified mergeability signals---such as explicitly minimizing gradient distance to a reference model or enforcing subspace alignment during training---may yield substantially larger gains. Additionally, merge-aware finetuning strategies that incorporate knowledge of the specific merge method to be used could further improve compatibility.

\paragraph{Implications.} These results support the broader hypothesis that mergeability is not an immutable property of task pairs but can be influenced through careful finetuning design. The gradient-based metrics identified by our analysis provide actionable targets for developing more principled merge-aware training procedures.
